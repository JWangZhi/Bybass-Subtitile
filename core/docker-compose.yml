# ============================================
# Bypass Subtitles - Docker Compose
# ============================================
# Usage:
#   CPU mode:  docker-compose up backend
#   GPU mode:  docker-compose up backend-gpu
#   Full stack: docker-compose up
# ============================================

services:
  # Backend (CPU mode - for cloud/serverless)
  backend:
    build:
      context: ./backend
      target: base
    ports:
      - "8765:8765"
    environment:
      - TRANSCRIPTION_MODE=auto
      - WHISPER_MODEL_SIZE=small
      - WHISPER_DEVICE=cpu
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - DEEPGRAM_API_KEYS=${DEEPGRAM_API_KEYS:-}
    volumes:
      - whisper-cache:/root/.cache/huggingface
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8765/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Backend (GPU mode - for local with NVIDIA GPU)
  backend-gpu:
    build:
      context: ./backend
      target: gpu
    ports:
      - "8765:8765"
    environment:
      - TRANSCRIPTION_MODE=auto
      - WHISPER_MODEL_SIZE=small
      - WHISPER_DEVICE=cuda
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - DEEPGRAM_API_KEYS=${DEEPGRAM_API_KEYS:-}
    volumes:
      - whisper-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    restart: unless-stopped
    profiles:
      - gpu

  # Landing Page (Next.js)
  landing:
    build:
      context: ../landing
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8765
    depends_on:
      - backend
    restart: unless-stopped

volumes:
  whisper-cache:
